# CombinedLossのパラメータ調整の手順

このドキュメントでは、CombinedLoss関数のパラメータ調整方法について説明します。

## はじめに：ユーザーからの質問

**質問:** スクショ画像からの抜粋ですが、下記コードのパラメータを調整して最適なパフォーマンスを探すことになりました。が、このパラメータに関して全然詳しくありません。素人にもわかりやすく教えてくださいますでしょうか？

```python
class CombinedLoss(nn.Module):
    def __init__(self, alpha=1, gamma=3, bce_weight=0.5, focal_weight=0.5): #gamma2
```

## CombinedLossの目的と役割

この損失関数は、機械学習モデルの「間違い」を評価するための特別な計算方法です。具体的には、「Binary Cross Entropy Loss (BCE損失)」と「Focal Loss」という2つの計算方法を組み合わせたものです。

主に以下のような状況で役立ちます：

*   **クラス不均衡**: 例えば、1000枚の画像のうち、犬の画像が900枚、猫の画像が100枚しかない場合など、データの種類に偏りがある場合に、少ない方のデータ（この場合は猫）もしっかり学習できるようにします。
*   **簡単なサンプルと難しいサンプルのバランス**: モデルが簡単に正解できるサンプルばかりに注目するのではなく、間違えやすい難しいサンプルにもっと注意を払うように仕向けます。

## 各パラメータの説明

この `__init__` メソッドの中にある `alpha`, `gamma`, `bce_weight`, `focal_weight` が調整するパラメータです。

1.  **`bce_weight` (BCE損失の重み)**
    *   **役割**: これは、CombinedLoss全体の中で、「BCE損失」という計算方法をどれくらいの割合で重視するかを決める重みです。
    *   **イメージ**: 例えば、料理のレシピで、塩と砂糖のどちらを多めに入れるか、というようなバランス調整です。
    *   **値**: `0.5` というのは、BCE損失とFocal Lossを同じくらい重視するという意味です（合計で1になるように正規化されることが多いですが、このコードでは直接的な重みとして使われているようです）。この値を大きくするとBCE損失の影響が強くなり、小さくすると弱くなります。
    *   **BCE損失とは？**: これは、主に「はい」か「いいえ」の2択（二値分類）や、各カテゴリに属するか否かを判断するような問題で使われる、基本的な間違いの測り方です。

2.  **`focal_weight` (Focal Lossの重み)**
    *   **役割**: これは、CombinedLoss全体の中で、「Focal Loss」という計算方法をどれくらいの割合で重視するかを決める重みです。
    *   **イメージ**: 上記の `bce_weight` と対になるもので、料理のレシピでいうもう一方の調味料の量です。
    *   **値**: `0.5` というのは、Focal LossとBCE損失を同じくらい重視するという意味です。この値を大きくするとFocal Lossの影響が強くなり、小さくすると弱くなります。
    *   **Focal Lossとは？**: これはBCE損失を改良したもので、特にクラス不均衡（データの種類に偏りがある場合）や、モデルが簡単に正解できてしまうサンプルからの影響を減らし、間違えやすい難しいサンプルに学習を集中させたい場合に有効な間違いの測り方です。

3.  **`alpha` (アルファ)**
    *   **役割**: このパラメータは、主に「Focal Loss」の中で使われ、クラス間の不均衡を調整する役割があります。 特に、ポジティブクラス（検出したい対象）とネガティブクラス（それ以外）の重要度を調整します。
    *   **イメージ**: 例えば、希少な病気を見つけるモデルを作る場合、健康な人のデータがたくさんあっても、病気の人をしっかり見つけられるように、「病気の人の間違い」の方をより重要視する、といった調整です。
    *   **値**: 通常0から1の間の値をとり、例えば `alpha` が `0.25` ならポジティブクラスの重みが0.25、ネガティブクラスの重みが0.75のようになります（実装によります）。`1` に設定されている場合、このαによる重み付けを無効化、あるいは特定のクラスに最大限の重みを置いている可能性があります。このコードでは `alpha` の具体的な使われ方（どちらのクラスを重視するかなど）までは見えませんが、一般的には少数派クラスの重要度を上げるために使われます。

4.  **`gamma` (ガンマ)**
    *   **役割**: このパラメータも「Focal Loss」の中で使われ、簡単なサンプルからの損失の寄与を減らし、難しいサンプル（モデルが間違えやすいもの）に学習を集中させる度合いを調整します。
    *   **イメージ**: テスト勉強で、もう完璧に覚えている簡単な問題はほどほどにして、まだよく間違える難しい問題に時間を割くようなイメージです。
    *   **値**: `gamma` が0の場合、Focal LossはBCE損失と同じになります。`gamma` を大きくするほど（例えば `2`, `3`, `5`など）、簡単なサンプルの影響がより小さくなり、難しいサンプルへの集中度が高まります。 ここでは `3` と設定されているので、比較的強く難しいサンプルに焦点を当てる設定と言えます。

## パラメータ調整の基本方針

*   **`bce_weight` と `focal_weight`**: まずは、BCE損失とFocal Lossのどちらを主軸にするか、あるいはどの程度のバランスで混ぜるかを決めます。データが不均衡だったり、難しいサンプルに手こずっているようであれば `focal_weight` を高めに設定することを検討します。
*   **`alpha` (Focal Loss内)**: クラス不均衡が顕著な場合（例えば、検出したいものがごく少数しかない場合）、少数派クラスの `alpha` の値を調整して、そのクラスの間違いに対するペナルティを重くすることを検討します。
*   **`gamma` (Focal Loss内)**: モデルが簡単なサンプルはすぐに学習してしまうけれど、難しいサンプルで精度が上がらない場合に、`gamma` の値を大きくして、難しいサンプルへの学習を強化することを検討します。ただし、大きくしすぎると学習が不安定になることもあります。

## 効率的なパラメータ調整手順

限られた回数（例：週に10回）でCVスコアを最大化するための具体的な調整計画を以下に提案します：

### フェーズ1：ベースライン測定と損失バランスの探索 (計4回)

*   **試行1 (ベースライン):**
    *   `alpha=1`, `gamma=3`, `bce_weight=0.5`, `focal_weight=0.5`
    *   目的: 現在の初期設定でのCVスコアを記録し、比較の基準とする。

*   **試行2 (Focal Loss重視):**
    *   `alpha=1`, `gamma=3`, `bce_weight=0.2`, `focal_weight=0.8`
    *   目的: Focal Lossの影響を強めた場合の効果を見る。

*   **試行3 (BCE Loss重視):**
    *   `alpha=1`, `gamma=3`, `bce_weight=0.8`, `focal_weight=0.2`
    *   目的: BCE Lossの影響を強めた場合の効果を見る。

*   **試行4 (Focal Lossのみ):**
    *   `alpha=1`, `gamma=3`, `bce_weight=0.0`, `focal_weight=1.0`
    *   目的: Focal Loss単体での性能を見る。

*   **フェーズ1評価:** 試行1〜4の結果を比較し、最もCVスコアが高かった `bce_weight` と `focal_weight` の組み合わせを見つける。

### フェーズ2：`gamma` 値の探索 (計4回)

フェーズ1で最も良かった `bce_weight`/`focal_weight` の比率を固定し、`gamma` の値を変更する：

*   **試行5 (`gamma` を下げる):**
    *   `alpha=1`, `gamma=1`, `bce_weight`=(フェーズ1最適値), `focal_weight`=(フェーズ1最適値)
    *   目的: 難しいサンプルへの集中度を下げた場合の効果を見る。

*   **試行6 (`gamma` を少し下げる):**
    *   `alpha=1`, `gamma=2`, `bce_weight`=(フェーズ1最適値), `focal_weight`=(フェーズ1最適値)
    *   目的: 初期値より少し集中度を下げた場合の効果を見る。

*   **試行7 (`gamma` を上げる):**
    *   `alpha=1`, `gamma=4`, `bce_weight`=(フェーズ1最適値), `focal_weight`=(フェーズ1最適値)
    *   目的: 初期値より集中度を上げた場合の効果を見る。

*   **試行8 (`gamma` をさらに上げる):**
    *   `alpha=1`, `gamma=5`, `bce_weight`=(フェーズ1最適値), `focal_weight`=(フェーズ1最適値)
    *   目的: さらに集中度を上げた場合の効果を見る。

### フェーズ3：微調整と確認 (計2回)

*   **試行9 (最有望設定の微調整 or `alpha` 探索):**
    *   **選択肢A (微調整):** 最適bce/focal比率 + 最適gammaの組み合わせで、さらに細かい値を試す。
    *   **選択肢B (`alpha` 探索):** もし可能なら、`alpha=0.5` などを試す。

*   **試行10 (最終確認 or さらなる微調整):**
    *   試行9の結果を踏まえ、最も良かったパラメータの組み合わせで最終確認か、さらなる微調整を行う。

## パラメータ探索の記録表

効率的に探索を進めるために、以下のような表を作成し、各試行の結果を記録することをお勧めします：

| 試行回数 | alpha | gamma | bce_weight | focal_weight | CVスコア | メモ                 |
| :------- | :---- | :---- | :--------- | :----------- | :------- | :------------------- |
| 1        | 1     | 3     | 0.5        | 0.5          |          | ベースライン         |
| 2        | 1     | 3     | 0.2        | 0.8          |          | Focal重視            |
| 3        | 1     | 3     | 0.8        | 0.2          |          | BCE重視              |
| 4        | 1     | 3     | 0.0        | 1.0          |          | Focal単体            |
| 5-10     | ...   | ...   | ...        | ...          |          | フェーズ2,3の試行    |
